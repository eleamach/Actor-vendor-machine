{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtv_4JVzd15X"
      },
      "source": [
        "# **\"Actor vendor\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZE1VD1keJxe"
      },
      "source": [
        "## ***PART 1 - Data collect***\n",
        "\n",
        "\n",
        "> This code retrieves information about actors from Wikidata using a SPARQL query, downloads their images, extracts EXIF metadata and dominant colors from the images, and stores all the information in a JSON file for further analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmqCf3x2Rz5h"
      },
      "outputs": [],
      "source": [
        "# Installation\n",
        "!pip install sparqlwrapper\n",
        "!pip install ipywidgets\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install exifread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA8hnZ-uV5y4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plot\n",
        "import matplotlib.colors as mcolors\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "from PIL import Image\n",
        "from PIL.ExifTags import TAGS\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
        "\n",
        "print(\"Query asked ...\")\n",
        "\n",
        "# Query to get actor\n",
        "query = \"\"\"SELECT ?actor ?actorLabel ?image ?height ?hairColor ?filmStyle ?nationality ?placeOfBirth ?careerStart ?dateOfDeath WHERE {\n",
        "  ?actor wdt:P21 wd:Q6581097;                        # Men\n",
        "          wdt:P106 wd:Q33999;                         # Actor\n",
        "          wdt:P18 ?image.                             # Image\n",
        "  OPTIONAL { ?actor wdt:P570 ?dateOfDeath }          # Death\n",
        "  FILTER(!BOUND(?dateOfDeath))                        # Alive\n",
        "  FILTER EXISTS { ?actor wdt:P18 ?image }            # Only with an image\n",
        "  FILTER(STRENDS(str(?image), \".jpg\"))                # Only jpg\n",
        "  OPTIONAL { ?actor wdt:P2048 ?height. }             # Height\n",
        "  OPTIONAL { ?actor wdt:P1884 ?hairColor. }          # Hair color\n",
        "  OPTIONAL { ?actor wdt:P2515 ?filmStyle. }          # Kind of film\n",
        "  OPTIONAL { ?actor wdt:P27 ?nationality. }          # Nationality\n",
        "  OPTIONAL { ?actor wdt:P19 ?placeOfBirth. }         # Where he was born\n",
        "  OPTIONAL { ?actor wdt:P2031 ?careerStart. }        # Year he debuted\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "}\n",
        "LIMIT 100\"\"\"\n",
        "\n",
        "# Get result of the query\n",
        "def get_results(endpoint_url, query):\n",
        "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
        "        sys.version_info[0],\n",
        "        sys.version_info[1],)\n",
        "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
        "    sparql.setQuery(query)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    return sparql.query().convert()\n",
        "\n",
        "array = []\n",
        "results = get_results(endpoint_url, query)\n",
        "\n",
        "# Format the result\n",
        "for result in results[\"results\"][\"bindings\"]:\n",
        "    array.append((result[\"actorLabel\"][\"value\"], result[\"image\"][\"value\"]))\n",
        "dataframe = pd.DataFrame(array, columns=[\"Actor\", \"Image\"])\n",
        "dataframe = dataframe.astype(dtype={\"Actor\": \"<U200\", \"Image\": \"<U200\"})\n",
        "\n",
        "print(\"Query responded and formatted\")\n",
        "\n",
        "# Where we will be putting our images\n",
        "output_folder = \"images/\"\n",
        "\n",
        "# Open our file imagesData.json\n",
        "if not os.path.isdir(os.path.join(output_folder)): os.mkdir(output_folder)\n",
        "f = open(\"./imagesData.json\", \"a\")\n",
        "\n",
        "print(\"Downloading images ...\")\n",
        "\n",
        "\n",
        "def simplify_color(rgb):\n",
        "    r, g, b = rgb\n",
        "    max_val = max(r, g, b)\n",
        "    if max_val == r:\n",
        "        return 'red'\n",
        "    elif max_val == g:\n",
        "        return 'green'\n",
        "    elif max_val == b:\n",
        "        return 'blue'\n",
        "    return 'Other'\n",
        "\n",
        "\n",
        "# Download images onto our output folder\n",
        "def download_image(url, index):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
        "    if request.status_code == 200:\n",
        "        extension = url.split(\".\")[-1]\n",
        "        filename = os.path.join(output_folder, f\"image_{index}.{extension}\") # How we want to name our file\n",
        "        with open(filename, \"wb\") as image:\n",
        "            request.raw.decode_content = True\n",
        "            shutil.copyfileobj(request.raw, image)\n",
        "        imgfile = Image.open(filename)\n",
        "        exif_data = imgfile._getexif()\n",
        "        img_exif_data = {}\n",
        "        if exif_data: # Only if there is exif data\n",
        "            local_exif_data_dict = {}\n",
        "            for tag, value in exif_data.items():\n",
        "                if tag in TAGS:\n",
        "                    if isinstance(value, bytes):\n",
        "                      try:\n",
        "                        value = value.decode('UTF-8')\n",
        "                      except Exception :\n",
        "                        value = \"Error in variable encoding\"\n",
        "                    local_exif_data_dict[TAGS[tag]] = str(value)\n",
        "        img_exif_data[filename] = local_exif_data_dict if exif_data else None\n",
        "    return request.status_code, img_exif_data\n",
        "\n",
        "all_exif_data = []\n",
        "\n",
        "for index, image_url in enumerate(dataframe.Image):\n",
        "    code, exif = download_image(image_url, index)\n",
        "    if not exif:  # If no EXIF data is available\n",
        "        exif = {\"Favorite\": \"NotFavorite\", \"DominantColor1\": \"Undefined\"}\n",
        "    all_exif_data.append(exif)\n",
        "\n",
        "    # Add code for dominant color here (after checking EXIF data)\n",
        "\n",
        "# Write exif data onto the json\n",
        "with open(\"./imagesData.json\", \"w\") as f:\n",
        "    json.dump(all_exif_data, f)\n",
        "\n",
        "print(\"JSON written\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Dominant color begin ...\")\n",
        "\n",
        "# Dominant color\n",
        "n = 1  # How many dominant color we want\n",
        "default_color = (255)\n",
        "image_folder = \"./images/\"\n",
        "image_files = os.listdir(image_folder)\n",
        "json_file = \"./imagesData.json\"\n",
        "\n",
        "for idx, image_file in enumerate(image_files):\n",
        "    if image_file.endswith(('.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        img = Image.open(image_path)\n",
        "        img = img.convert(\"RGB\")\n",
        "        np_img = np.array(img)\n",
        "\n",
        "        numarray = np.array(img.getdata(), np.uint8)\n",
        "        clusters = KMeans(n_clusters=n, n_init=2)\n",
        "        clusters.fit(numarray)\n",
        "        cluster_centers = clusters.cluster_centers_\n",
        "        colors_list = [tuple(map(int, cluster_centers[i])) for i in range(n)]\n",
        "\n",
        "        simplified_colors_list = [simplify_color(color) for color in colors_list]  # Simplify colors\n",
        "\n",
        "        # Update the JSON data part as below\n",
        "        with open(json_file, 'r+') as f:\n",
        "            data = json.load(f)\n",
        "            image_key = f\"images/image_{idx}.jpg\"\n",
        "            if data[idx].get(image_key):\n",
        "                for i, color in enumerate(simplified_colors_list, start=1):\n",
        "                    data[idx][image_key][f\"Favorite\"] = \"NotFavorite\"\n",
        "                    data[idx][image_key][f\"DominantColor{i}\"] = color\n",
        "                f.seek(0)\n",
        "                json.dump(data, f, indent=4)\n",
        "                f.truncate()\n",
        "\n",
        "\n",
        "print(\"Dominant color done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNp0Q40bBpd1"
      },
      "source": [
        "##***PART 2 AND 3 - Labeling, annotation, and analysis***\n",
        "\n",
        "> This code creates a grid layout using the ipywidgets library to display images, checkboxes, and text input fields. It chooses only the 20 first downloaded images. It allows users to mark images as favorites and add tags to them. Upon clicking the \"Select\" button, the selected images' metadata, including their favorite status and tags, are updated in JSON files.  \n",
        "\n",
        "\n",
        "What you need to do :\n",
        "* Check your favorite images so that on the code below, new images will be recommended to you\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxCyzCGNBrSS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from ipywidgets import GridspecLayout, Image, Checkbox, Text, Button, Output\n",
        "# Get paths to images in the folder\n",
        "image_folder = \"./images\"\n",
        "image_paths = [os.path.join(image_folder, f'image_{i}.jpg') for i in range(20)]\n",
        "\n",
        "# Define JSON file\n",
        "json_file = \"./imagesData.json\"\n",
        "\n",
        "# Read JSON file to get data\n",
        "with open(json_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Filter images based on the \"Favorite\" tag\n",
        "favorite_image_paths = [entry for entry in data if entry and isinstance(entry, dict)]\n",
        "num_images = min(len(favorite_image_paths), 20)\n",
        "\n",
        "# Generate widgets for each image\n",
        "checkboxes = [Checkbox(value=False, description='Favorite') for _ in range(num_images)]\n",
        "tag_inputs = [Text(placeholder='Enter tag', description='Tag') for _ in range(num_images)]\n",
        "\n",
        "# Calculate the number of columns for the grid\n",
        "num_columns = 1\n",
        "\n",
        "# Calculate the number of rows needed based on the total number of images and the number of columns\n",
        "num_rows = (num_images + num_columns - 1) // num_columns\n",
        "\n",
        "# Create the layout grid\n",
        "layout = GridspecLayout(n_columns=num_columns * 3, n_rows=num_rows, width='1300px')\n",
        "\n",
        "def get_selected_images(btn):\n",
        "    global labels  # Utilisez global pour modifier la variable labels globale\n",
        "    labels = []  # Réinitialiser la liste des étiquettes à chaque fois que le bouton est cliqué\n",
        "\n",
        "    with open(json_file, 'r+') as f:\n",
        "        data = json.load(f)\n",
        "        for i, (checkbox, tag_input) in enumerate(zip(checkboxes, tag_inputs)):\n",
        "            is_favorite = checkbox.value\n",
        "            tag = tag_input.value\n",
        "            image_key = f\"images/image_{i}.jpg\"\n",
        "            if is_favorite:\n",
        "                test = \"Favorite\"\n",
        "                labels.append(\"Favorite\")\n",
        "            else:\n",
        "                test = \"NotFavorite\"\n",
        "                labels.append(\"NotFavorite\")\n",
        "            if i < len(data):\n",
        "                if data[i].get(image_key):\n",
        "                    if data[i][image_key][\"Favorite\"] == \"NotFavorite\":\n",
        "                        data[i][image_key][\"Favorite\"] = test\n",
        "                        data[i][image_key][\"Tag\"] = tag\n",
        "                        continue\n",
        "    for i in range(80):\n",
        "        labels.append(\"NotFavorite\")\n",
        "\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "    print(\"Data written\")\n",
        "\n",
        "def get_reset(btn):\n",
        "    result = []\n",
        "    with open(json_file, 'r+') as f:\n",
        "        data = json.load(f)\n",
        "        for i, (checkbox, tag_input) in enumerate(zip(checkboxes, tag_inputs)):\n",
        "            image_key = f\"images/image_{i}.jpg\"\n",
        "\n",
        "            if i < len(data):\n",
        "                if data[i].get(image_key):\n",
        "                    if data[i][image_key][\"Favorite\"] == \"Favorite\":\n",
        "                        data[i][image_key][\"Favorite\"] = \"NotFavorite\"\n",
        "                        data[i][image_key][\"Tag\"] = \"\"\n",
        "                        continue\n",
        "\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    print(\"Data written\")\n",
        "\n",
        "# Button to select images\n",
        "buttonAdd = Button(description=\"Select\")\n",
        "buttonReset = Button(description=\"Reset\")\n",
        "\n",
        "# Output to display results\n",
        "output = Output()\n",
        "\n",
        "# Fill the grid with images, checkboxes, and text fields\n",
        "for i in range(num_images):\n",
        "    image_entry = favorite_image_paths[i]\n",
        "    image_path = list(image_entry.keys())[0]\n",
        "    with open(image_path, \"rb\") as file:\n",
        "        image = file.read()\n",
        "    image_widget = Image(\n",
        "        value=image,\n",
        "        format='jpg',\n",
        "        width=100,\n",
        "        height=100,\n",
        "    )\n",
        "    row = i // num_columns\n",
        "    col = (i % num_columns)\n",
        "    layout[row, col] = image_widget\n",
        "    layout[row, col + 1] = checkboxes[i]\n",
        "    layout[row, col + 2] = tag_inputs[i]\n",
        "\n",
        "# Link button click to function\n",
        "buttonAdd.on_click(get_selected_images)\n",
        "buttonReset.on_click(get_reset)\n",
        "\n",
        "# Display the grid, button, and output\n",
        "display(layout, buttonAdd, buttonReset, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz3Fm7MaQ9b1"
      },
      "source": [
        "## ***PART 4 - Data vizualisation***\n",
        "\n",
        "> This code reads image metadata from a JSON file, extracts relevant information such as image sizes, orientations, camera models, and colors. It then visualizes the extracted data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWjLzYljXZ7Q"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open(\"./imagesData.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "image_data = []\n",
        "image_sizes = []\n",
        "orientations = []\n",
        "colors = []\n",
        "camera_models = []\n",
        "favorite = []\n",
        "\n",
        "# Extract exif data\n",
        "for item in data:\n",
        "    for image_path, exif_data in item.items():\n",
        "        if exif_data:\n",
        "            # Size\n",
        "            if 'ExifImageWidth' in exif_data and 'ExifImageHeight' in exif_data:\n",
        "                image_sizes.append((exif_data['ExifImageWidth'], exif_data['ExifImageHeight']))\n",
        "\n",
        "            # Orientation\n",
        "            if 'Orientation' in exif_data:\n",
        "                orientations.append(exif_data['Orientation'])\n",
        "\n",
        "            # Camera model\n",
        "            if 'Model' in exif_data:\n",
        "                camera_models.append(exif_data['Model'])\n",
        "\n",
        "                # Favorite\n",
        "            if 'Favorite' in exif_data:\n",
        "                favorite.append(exif_data['Favorite'])\n",
        "\n",
        "            # Year\n",
        "            if 'DateTimeOriginal' in exif_data:\n",
        "                image_data.append(exif_data['DateTimeOriginal'][:4])\n",
        "\n",
        "            # Colors\n",
        "            for color_key in ['DominantColor1', 'DominantColor2', 'DominantColor3']:\n",
        "                if color_key in exif_data:\n",
        "                    colors.append(exif_data[color_key])  # Directly append the RGB values\n",
        "\n",
        "# Convert and clean up\n",
        "df = pd.DataFrame({'DateTimeOriginal': pd.to_datetime(image_data, format='%Y')})\n",
        "sizes_df = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "orientations_df = pd.DataFrame(orientations, columns=['Orientation'])\n",
        "camera_models_df = pd.DataFrame(camera_models, columns=['Camera Model'])\n",
        "favorite_df = pd.DataFrame(favorite, columns=['Favorite'])\n",
        "color_df = pd.DataFrame(colors, columns=['Colors'])\n",
        "\n",
        "# Grouping\n",
        "grouped = df.groupby(df['DateTimeOriginal'].dt.year).size()\n",
        "sizes_count = sizes_df.groupby(['Width', 'Height']).size()\n",
        "orientations_count = orientations_df.groupby(['Orientation']).size()\n",
        "camera_models_count = camera_models_df.groupby(['Camera Model']).size()\n",
        "favorite_count = favorite_df.groupby(['Favorite']).size()\n",
        "colors_count = color_df.groupby(['Colors']).size()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(25, 15))\n",
        "\n",
        "# Image sizes\n",
        "plt.subplot(2, 3, 1)\n",
        "sizes_count.plot(kind='bar', title='Number of images per size')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Orientations\n",
        "plt.subplot(2, 3, 2)\n",
        "orientations_count.plot(kind='bar', title='Number of images per orientation')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Camera models\n",
        "plt.subplot(2, 3, 3)\n",
        "camera_models_count.plot(kind='bar', title='Number of images per camera model')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Images per year\n",
        "plt.subplot(2, 3, 4)\n",
        "grouped.plot(kind='bar', title='Number of images per year')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Colors\n",
        "plt.subplot(2, 3, 5)\n",
        "colors_count.plot(kind='bar', title='Number of images per dominant color', xlabel='Dominant color', ylabel='Number')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Favorite\n",
        "plt.subplot(2, 3, 6)\n",
        "favorite_count.plot(kind='bar', title='Number of favorite images')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmKB0kf1RTZ7"
      },
      "source": [
        "## ***PART 5 - RECOMMENDATION***\n",
        "\n",
        "\n",
        "\n",
        "> This code loads image metadata from our JSON file, identifies a favorite image, performs K-means clustering to group similar images, recommends similar items based on the favorite image.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAhPWMraHOKr"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "from sklearn.metrics import adjusted_rand_score, homogeneity_completeness_v_measure, silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Load image data from JSON file\n",
        "with open(\"./imagesData.json\") as f:\n",
        "    image_data = json.load(f)\n",
        "\n",
        "# Find the image marked as \"Favorite\"\n",
        "favorite_image_data = None\n",
        "for item in image_data:\n",
        "    for image_path, exif_data in item.items():\n",
        "        if exif_data and 'Favorite' in exif_data and exif_data['Favorite'] == \"Favorite\":\n",
        "            favorite_image_data = exif_data\n",
        "            break\n",
        "\n",
        "if favorite_image_data is None:\n",
        "    print(\"No favorite image found.\")\n",
        "    exit()\n",
        "\n",
        "data = []\n",
        "\n",
        "# Extract exif data\n",
        "for item in image_data:\n",
        "    for image_path, exif_data in item.items():\n",
        "        info_to_train_list = []  # Create a new list for each image\n",
        "\n",
        "        # Orientation\n",
        "        orientation_default = \"\"\n",
        "        if exif_data:\n",
        "            info_to_train_list.append(exif_data.get('Orientation', orientation_default))\n",
        "        else:\n",
        "            info_to_train_list.append(orientation_default)\n",
        "        # Camera model\n",
        "        model_default = \"\"\n",
        "        if exif_data:\n",
        "            info_to_train_list.append(exif_data.get('Model', model_default))\n",
        "        else:\n",
        "            info_to_train_list.append(model_default)\n",
        "        # Year\n",
        "        year_default = \"\"\n",
        "        if exif_data:\n",
        "            info_to_train_list.append(exif_data.get('DateTimeOriginal', \"\")[:4] or year_default)\n",
        "        else:\n",
        "            info_to_train_list.append(year_default)\n",
        "        # Colors\n",
        "        color_default = \"\"\n",
        "        if exif_data:\n",
        "            info_to_train_list.append(exif_data.get('DominantColor1', color_default))  # Use default if key not present\n",
        "        else:\n",
        "            info_to_train_list.append(color_default)\n",
        "\n",
        "        # Add the extracted information for the current image to data\n",
        "        data.append(info_to_train_list)\n",
        "\n",
        "# Encode categorical features and labels\n",
        "label_encoders = [LabelEncoder() for _ in range(len(data[0]))]\n",
        "encoded_data = []\n",
        "for i, column in enumerate(zip(*data)):\n",
        "    encoded_data.append(label_encoders[i].fit_transform(column))\n",
        "\n",
        "X = list(zip(*encoded_data))  # Features\n",
        "y = labels  # Labels\n",
        "\n",
        "# Clustering\n",
        "k = 7  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=k, n_init=10)\n",
        "kmeans.fit(X)\n",
        "clusters = kmeans.labels_\n",
        "\n",
        "# Add the cluster labels to the original data\n",
        "data_with_clusters = pd.DataFrame(data, columns=[\"Orientation\", \"CameraModel\", \"Year\", \"DominantColor\"])\n",
        "data_with_clusters[\"Cluster\"] = clusters\n",
        "\n",
        "# Recommendation function\n",
        "def recommend_items(cluster, data_with_clusters):\n",
        "    items_in_cluster = data_with_clusters[data_with_clusters[\"Cluster\"] == cluster]\n",
        "    recommended_items = items_in_cluster.sample(n=3)  # Sample 3 items from the cluster\n",
        "    return recommended_items\n",
        "\n",
        "# Use favorite image data for recommendation\n",
        "encoded_item = []\n",
        "for i, key in enumerate(['Orientation', 'Model', 'DateTimeOriginal', 'DominantColor1']):\n",
        "    if key in favorite_image_data:\n",
        "        val = favorite_image_data[key]\n",
        "        encoded_item.append(label_encoders[i].transform([val])[0])\n",
        "    else:\n",
        "        # Handle the case where the key is missing\n",
        "        # For instance, you could append a default value or skip this item\n",
        "        if key == 'Orientation':\n",
        "            encoded_item.append(\"0\")\n",
        "        elif key == 'Model':\n",
        "            encoded_item.append(\"0\")\n",
        "        elif key == 'DateTimeOriginal':\n",
        "            encoded_item.append(\"2000\")\n",
        "        elif key == 'DominantColor1':\n",
        "            encoded_item.append(\"Undefined\")\n",
        "\n",
        "# Now proceed with prediction using encoded_item\n",
        "# Predict the cluster for the favorite image\n",
        "cluster = kmeans.predict([encoded_item])[0]\n",
        "\n",
        "# Use the predicted cluster for recommendation\n",
        "recommendations = recommend_items(cluster, data_with_clusters)\n",
        "\n",
        "# Display favorite image data\n",
        "print(\"Favorite image data:\")\n",
        "print(favorite_image_data.get(\"Orientation\", \"N/A\"))\n",
        "print(favorite_image_data.get(\"Model\", \"N/A\"))\n",
        "print(favorite_image_data.get(\"DateTimeOriginal\", \"N/A\")[:4])\n",
        "print(favorite_image_data.get(\"DominantColor1\", \"N/A\"))\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"Recommended items based on favorite image:\")\n",
        "print(recommendations)\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"Images:\")\n",
        "\n",
        "# Define num_images and num_columns\n",
        "num_images = len(recommendations)\n",
        "\n",
        "# Define layout\n",
        "layout = widgets.GridBox(layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
        "image_paths = [key for item in image_data for key in item.keys()]\n",
        "\n",
        "# Define layout\n",
        "layout = widgets.GridBox(layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
        "\n",
        "for i, image_path in enumerate(image_paths[:num_images]):\n",
        "    image_widget = widgets.Image(value=open(image_path, \"rb\").read(), format='jpg', width=100, height=100)\n",
        "    row = i\n",
        "    col = i\n",
        "    layout.children += (image_widget,)\n",
        "\n",
        "display(layout)\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"Metrics\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the logistic regression classifier\n",
        "classifier = svm.SVC()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Analyze important features (support vectors)\n",
        "support_vectors = classifier.support_vectors_\n",
        "dual_coef = classifier.dual_coef_[0]  # Dual coefficients of support vectors\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avg = silhouette_score(X, clusters)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "# Adjusted Rand Index\n",
        "ari = adjusted_rand_score(labels, clusters)\n",
        "print(\"Adjusted Rand Index:\", ari)\n",
        "\n",
        "# Homogeneity, Completeness, and V-measure\n",
        "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(labels, clusters)\n",
        "print(\"Homogeneity:\", homogeneity)\n",
        "print(\"Completeness:\", completeness)\n",
        "print(\"V-measure:\", v_measure)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "vZE1VD1keJxe",
        "ZNp0Q40bBpd1"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}